{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "This notebook deals with the classification of 2024 and 2025 images of personalities using VGG-19 CNN model with the insights of images in the pre-covid era."
      ],
      "metadata": {
        "id": "XFB0S-kGMg7t"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "1) Mount Google Drive."
      ],
      "metadata": {
        "id": "2YppFjZQMRxr"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGSX2dr7MR8K",
        "outputId": "6297d345-c09c-406d-89df-faef2f1ca522"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2) Let us inspect the pre-covid dataset which is the train dataset.\n",
        "\n",
        "The inspections of the total number of images, channels and sizes of the images are displayed."
      ],
      "metadata": {
        "id": "OvYS2jB8M4PR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "base_path = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Training-Validation Set/Sampled\"\n",
        "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tif', '.tiff'}\n",
        "\n",
        "total_images = 0\n",
        "folder_stats = {}\n",
        "\n",
        "for folder_name in sorted(os.listdir(base_path)):\n",
        "    folder_path = os.path.join(base_path, folder_name)\n",
        "    if not os.path.isdir(folder_path):\n",
        "        continue\n",
        "\n",
        "    dims_counter = Counter()\n",
        "    channel_counter = Counter()\n",
        "    format_counter = Counter()\n",
        "    count = 0\n",
        "\n",
        "    for fname in os.listdir(folder_path):\n",
        "        _, ext = os.path.splitext(fname.lower())\n",
        "        if ext not in IMAGE_EXTS:\n",
        "            continue\n",
        "        img_path = os.path.join(folder_path, fname)\n",
        "        try:\n",
        "            with Image.open(img_path) as img:\n",
        "                width, height = img.size\n",
        "                mode = img.mode\n",
        "                fmt = img.format  # Format like JPEG, PNG, etc.\n",
        "\n",
        "            dims_counter[(width, height)] += 1\n",
        "            channel_counter[mode] += 1\n",
        "            format_counter[fmt] += 1\n",
        "            count += 1\n",
        "        except Exception as e:\n",
        "            print(f\"Error reading {img_path}: {e}\")\n",
        "            continue\n",
        "\n",
        "    folder_stats[folder_name] = {\n",
        "        \"num_images\": count,\n",
        "        \"dims_counter\": dims_counter,\n",
        "        \"channel_counter\": channel_counter,\n",
        "        \"format_counter\": format_counter\n",
        "    }\n",
        "    total_images += count\n",
        "\n",
        "# Display results\n",
        "for folder_name, stats in folder_stats.items():\n",
        "    print(f\"Folder: {folder_name}\")\n",
        "    print(f\"  Number of images: {stats['num_images']}\")\n",
        "\n",
        "    if stats[\"dims_counter\"]:\n",
        "        common_dims, common_dims_count = stats[\"dims_counter\"].most_common(1)[0]\n",
        "        print(f\"  Most common size: {common_dims} (n={common_dims_count})\")\n",
        "        print(f\"  Unique sizes: {len(stats['dims_counter'])}\")\n",
        "    else:\n",
        "        print(\"  No valid image sizes found.\")\n",
        "\n",
        "    print(f\"  Channel modes: {dict(stats['channel_counter'])}\")\n",
        "    print(f\"  Image formats: {dict(stats['format_counter'])}\")\n",
        "    print(\"-\" * 40)\n",
        "\n",
        "print(f\"Total number of images across all folders: {total_images}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gx73Bb5tM4Zj",
        "outputId": "f0b6cb0f-4f4a-4e3d-f5fa-9fdba42af916"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder: Barack Obama\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Bill Gates\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Donald Trump\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Elon Musk\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Jeff Bezos\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Mark Zuckerberg\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Narendra Modi\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Folder: Virat Kohli\n",
            "  Number of images: 300\n",
            "  Most common size: (224, 224) (n=300)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 300}\n",
            "  Image formats: {'PNG': 300}\n",
            "----------------------------------------\n",
            "Total number of images across all folders: 2400\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. Let us inspect the 2024, and 2025 dataset.\n",
        "\n",
        "The inspections of the total number of images, channels and sizes of the images are displayed."
      ],
      "metadata": {
        "id": "n1mmBwDiNA7X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from collections import Counter\n",
        "from PIL import Image\n",
        "\n",
        "folder_path = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Testing Set/Unlabelled Test Data/Test Data\"\n",
        "\n",
        "# Common image extensions to consider\n",
        "IMAGE_EXTS = {'.jpg', '.jpeg', '.png', '.bmp', '.gif', '.tif', '.tiff', '.webp'}\n",
        "\n",
        "dims_counter   = Counter()\n",
        "mode_counter   = Counter()  # channel modes (RGB/L/RGBA/CMYK/…)\n",
        "format_counter = Counter()  # file formats (JPEG/PNG/…)\n",
        "ext_counter    = Counter()  # file extensions seen on disk\n",
        "count = 0\n",
        "\n",
        "for fname in os.listdir(folder_path):\n",
        "    fpath = os.path.join(folder_path, fname)\n",
        "    if not os.path.isfile(fpath):\n",
        "        continue\n",
        "    _, ext = os.path.splitext(fname.lower())\n",
        "    if ext not in IMAGE_EXTS:\n",
        "        continue\n",
        "\n",
        "    try:\n",
        "        with Image.open(fpath) as img:\n",
        "            w, h   = img.size         # width, height\n",
        "            mode   = img.mode         # RGB, L, RGBA, etc.\n",
        "            fmt    = img.format       # JPEG, PNG, etc. (from header)\n",
        "        dims_counter[(w, h)] += 1\n",
        "        mode_counter[mode]   += 1\n",
        "        format_counter[fmt]  += 1\n",
        "        ext_counter[ext]     += 1\n",
        "        count += 1\n",
        "    except Exception as e:\n",
        "        print(f\"Error reading {fpath}: {e}\")\n",
        "\n",
        "# ---- Display ----\n",
        "print(f\"Folder: {folder_path}\")\n",
        "print(f\"  Number of images: {count}\")\n",
        "\n",
        "if dims_counter:\n",
        "    (common_dims, common_n) = dims_counter.most_common(1)[0]\n",
        "    print(f\"  Most common size: {common_dims} (n={common_n})\")\n",
        "    print(f\"  Unique sizes: {len(dims_counter)}\")\n",
        "else:\n",
        "    print(\"  No valid image sizes found.\")\n",
        "\n",
        "print(f\"  Channel modes: {dict(mode_counter)}\")      # e.g., {'RGB': 238, 'L': 2}\n",
        "print(f\"  Image formats: {dict(format_counter)}\")    # e.g., {'JPEG': 200, 'PNG': 40}\n",
        "print(f\"  File extensions: {dict(ext_counter)}\")     # e.g., {'.jpg': 200, '.png': 40}\n",
        "\n",
        "print(f\"\\nTotal number of images across this folder: {count}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RFP0IoheNBEv",
        "outputId": "de7d6705-45be-4e63-f3cd-9284435c5047"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Folder: /content/drive/MyDrive/Applied Machine Learning/Preprocessing/Testing Set/Unlabelled Test Data/Test Data\n",
            "  Number of images: 240\n",
            "  Most common size: (224, 224) (n=240)\n",
            "  Unique sizes: 1\n",
            "  Channel modes: {'RGB': 240}\n",
            "  Image formats: {'PNG': 240}\n",
            "  File extensions: {'.png': 240}\n",
            "\n",
            "Total number of images across this folder: 240\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "4. We compute the mean and standard deviation from the training set and use them to normalize both training and test data. We then report statistics at three stages: before normalization, after normalization on a single batch, and after normalization over the full datasets."
      ],
      "metadata": {
        "id": "rB4E2HwnNFHc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os, glob\n",
        "from typing import List, Tuple\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "\n",
        "# ==== PATHS ====\n",
        "train_dir = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Training-Validation Set/Sampled\"\n",
        "test_dir  = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Testing Set/Unlabelled Test Data/Test Data\"  # single folder with images\n",
        "\n",
        "# ==== BASIC TRANSFORMS ====\n",
        "to_tensor = transforms.ToTensor()  # leaves values in [0,1] float\n",
        "\n",
        "# ==== CUSTOM DATASET FOR UNLABELLED TEST IMAGES ====\n",
        "class UnlabeledImageFolder(Dataset):\n",
        "    def __init__(self, root: str, transform=None, exts=(\".jpg\",\".jpeg\",\".png\",\".bmp\",\".tif\",\".tiff\",\".webp\")):\n",
        "        self.root = root\n",
        "        self.transform = transform\n",
        "        self.files: List[str] = []\n",
        "        for e in exts:\n",
        "            self.files += glob.glob(os.path.join(root, f\"*{e}\"))\n",
        "        self.files.sort()\n",
        "        if len(self.files) == 0:\n",
        "            raise FileNotFoundError(f\"No image files found in {root}\")\n",
        "    def __len__(self): return len(self.files)\n",
        "    def __getitem__(self, idx: int):\n",
        "        path = self.files[idx]\n",
        "        img = Image.open(path).convert(\"RGB\")  # force 3 channels\n",
        "        if self.transform: img = self.transform(img)\n",
        "        return img, -1\n",
        "\n",
        "# ==== 1) PRE-NORMALIZATION STATS FROM TRAIN ONLY ====\n",
        "train_ds_raw = datasets.ImageFolder(train_dir, transform=to_tensor)\n",
        "train_loader_raw = DataLoader(train_ds_raw, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "channel_sum = torch.zeros(3)\n",
        "channel_sq  = torch.zeros(3)\n",
        "pixels = 0\n",
        "\n",
        "for x, _ in tqdm(train_loader_raw, desc=\"Calculating TRAIN pre-norm stats\"):\n",
        "    bs, c, h, w = x.shape\n",
        "    pixels += bs*h*w\n",
        "    channel_sum += x.sum(dim=[0,2,3])\n",
        "    channel_sq  += (x**2).sum(dim=[0,2,3])\n",
        "\n",
        "train_mean = channel_sum / pixels\n",
        "train_std  = (channel_sq / pixels - train_mean**2).sqrt()\n",
        "\n",
        "print(\"Pre-normalization TRAIN mean:\", train_mean.tolist())\n",
        "print(\"Pre-normalization TRAIN std: \", train_std.tolist())\n",
        "\n",
        "# ==== 2) DEFINE NORMALIZE USING TRAIN STATS ====\n",
        "normalize = transforms.Normalize(mean=train_mean.tolist(), std=train_std.tolist())\n",
        "\n",
        "# ==== 3) NORMALIZED DATASETS ====\n",
        "train_ds = datasets.ImageFolder(train_dir, transform=transforms.Compose([to_tensor, normalize]))\n",
        "test_ds  = UnlabeledImageFolder(test_dir, transform=transforms.Compose([to_tensor, normalize]))\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "test_loader  = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# ---- one-batch post-norm stats (TRAIN) ----\n",
        "one_batch = next(iter(train_loader))[0]  # images only\n",
        "print(\"One-batch normalized TRAIN mean:\", one_batch.mean(dim=[0,2,3]).tolist())\n",
        "print(\"One-batch normalized TRAIN std: \", one_batch.std(dim=[0,2,3]).tolist())\n",
        "\n",
        "# ---- helper for full-dataset post-norm stats ----\n",
        "def full_stats(loader, desc: str) -> Tuple[torch.Tensor, torch.Tensor]:\n",
        "    ch_sum = torch.zeros(3)\n",
        "    ch_sq  = torch.zeros(3)\n",
        "    pix = 0\n",
        "    for x, _ in tqdm(loader, desc=desc):\n",
        "        bs, c, h, w = x.shape\n",
        "        pix += bs*h*w\n",
        "        ch_sum += x.sum(dim=[0,2,3])\n",
        "        ch_sq  += (x**2).sum(dim=[0,2,3])\n",
        "    mean = ch_sum / pix\n",
        "    std  = (ch_sq / pix - mean**2).sqrt()\n",
        "    return mean, std\n",
        "\n",
        "# ---- full-dataset post-norm stats ----\n",
        "train_norm_mean, train_norm_std = full_stats(train_loader, \"Full normalized TRAIN stats\")\n",
        "test_norm_mean,  test_norm_std  = full_stats(test_loader,  \"Full normalized TEST stats\")\n",
        "\n",
        "print(\"\\nFull normalized TRAIN mean:\", train_norm_mean.tolist())\n",
        "print(\"Full normalized TRAIN std: \", train_norm_std.tolist())\n",
        "print(\"Full normalized TEST mean:\",  test_norm_mean.tolist())\n",
        "print(\"Full normalized TEST std: \",  test_norm_std.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M74akSFFNFQx",
        "outputId": "1d3fd171-356a-4f4e-d53a-d91e6577f011"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Calculating TRAIN pre-norm stats: 100%|██████████| 38/38 [00:16<00:00,  2.26it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pre-normalization TRAIN mean: [0.6058028340339661, 0.4570693373680115, 0.40498921275138855]\n",
            "Pre-normalization TRAIN std:  [0.25304171442985535, 0.21776995062828064, 0.2149660289287567]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-batch normalized TRAIN mean: [-0.1684441864490509, -0.2336142659187317, -0.37765467166900635]\n",
            "One-batch normalized TRAIN std:  [1.0338082313537598, 0.987051784992218, 0.9565902948379517]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Full normalized TRAIN stats: 100%|██████████| 38/38 [00:17<00:00,  2.15it/s]\n",
            "Full normalized TEST stats: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Full normalized TRAIN mean: [2.2213475858734455e-07, -3.4643679214241274e-07, -2.275843229426755e-07]\n",
            "Full normalized TRAIN std:  [0.9999992251396179, 1.0000005960464478, 1.0000005960464478]\n",
            "Full normalized TEST mean: [-0.6195100545883179, -0.3517855107784271, -0.10748446732759476]\n",
            "Full normalized TEST std:  [1.2255595922470093, 1.2330907583236694, 1.2600317001342773]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "5. Let us do modelling with VGG-19 for classification of 2024, 2025 images of personalities with the knowledge from pre-covid images."
      ],
      "metadata": {
        "id": "TkgcWyOhNWd0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================\n",
        "# 8-person Face ID — VGG-19 + (Aida, Lion)\n",
        "# Prints Train/Test Acc, saves surname CMs + random surname% confidence overlays\n",
        "# Aida loaded dynamically from official repo (no pip packaging required)\n",
        "# ============================================\n",
        "\n",
        "import os, csv, math, random, re, sys, pathlib, importlib.util, subprocess\n",
        "import numpy as np, pandas as pd\n",
        "from PIL import Image\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from torchvision import models, transforms, datasets\n",
        "\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import cv2\n",
        "\n",
        "# -----------------------------\n",
        "# Paths\n",
        "# -----------------------------\n",
        "train_root = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Training-Validation Set/Sampled\"\n",
        "test_root  = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Testing Set/Unlabelled Test Data/Test Data\"\n",
        "test_csv   = \"/content/drive/MyDrive/Applied Machine Learning/Preprocessing/Testing Set/Unlabelled Test Data/Test.csv\"\n",
        "\n",
        "out_confmats   = \"/content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Confusion Matrices\"\n",
        "out_confimgs   = \"/content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Confidence Scores\"\n",
        "out_metricsdir = \"/content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Performance Metrics\"\n",
        "os.makedirs(out_confmats, exist_ok=True)\n",
        "os.makedirs(out_confimgs, exist_ok=True)\n",
        "os.makedirs(out_metricsdir, exist_ok=True)\n",
        "metrics_csv = os.path.join(out_metricsdir, \"VGG-19_RIC.csv\")\n",
        "\n",
        "# -----------------------------\n",
        "# Reproducibility\n",
        "# -----------------------------\n",
        "SEED = 1906525\n",
        "random.seed(SEED); np.random.seed(SEED); torch.manual_seed(SEED); torch.cuda.manual_seed_all(SEED)\n",
        "torch.backends.cudnn.deterministic = True\n",
        "torch.backends.cudnn.benchmark = False\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# -----------------------------\n",
        "# Normalization (our train stats)\n",
        "# -----------------------------\n",
        "MEAN = [0.6058028340339661, 0.4570693373680115, 0.40498921275138855]\n",
        "STD  = [0.25304171442985535, 0.21776995062828064, 0.2149660289287567]\n",
        "\n",
        "to_tensor_norm = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=MEAN, std=STD),\n",
        "])\n",
        "\n",
        "# -----------------------------\n",
        "# Datasets & Dataloaders\n",
        "# -----------------------------\n",
        "train_ds = datasets.ImageFolder(root=train_root, transform=to_tensor_norm)\n",
        "class_to_idx = train_ds.class_to_idx\n",
        "idx_to_class = {v:k for k,v in class_to_idx.items()}\n",
        "\n",
        "def surname_of(full_name: str) -> str:\n",
        "    parts = full_name.strip().split()\n",
        "    return parts[-1] if parts else full_name\n",
        "\n",
        "def initials_of(full_name: str) -> str:\n",
        "    parts = full_name.strip().split()\n",
        "    return f\"{parts[0][0]}{parts[-1][0]}\".upper() if len(parts)>=2 else full_name[:2].upper()\n",
        "\n",
        "surname_ticks = [surname_of(idx_to_class[i]) for i in range(len(idx_to_class))]\n",
        "\n",
        "train_loader       = DataLoader(train_ds, batch_size=32, shuffle=True,  num_workers=2, pin_memory=True)\n",
        "train_eval_loader  = DataLoader(train_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "class CSVTestDataset(Dataset):\n",
        "    def __init__(self, root_dir, csv_path, transform=None, class_to_idx=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        df = pd.read_csv(csv_path)\n",
        "        assert {\"Image Name\",\"Class Name\"}.issubset(df.columns), \"CSV must have 'Image Name' and 'Class Name'\"\n",
        "        self.samples = []\n",
        "        for _, row in df.iterrows():\n",
        "            img_name = str(row[\"Image Name\"])\n",
        "            cls_name = str(row[\"Class Name\"])\n",
        "            p = os.path.join(root_dir, img_name)\n",
        "            if not os.path.exists(p):\n",
        "                alt = os.path.join(root_dir, cls_name, img_name)\n",
        "                if os.path.exists(alt): p = alt\n",
        "            self.samples.append((p, class_to_idx[cls_name], img_name, cls_name))\n",
        "    def __len__(self): return len(self.samples)\n",
        "    def __getitem__(self, i):\n",
        "        p, y, img_name, cls_name = self.samples[i]\n",
        "        im = Image.open(p).convert(\"RGB\")\n",
        "        if self.transform: im = self.transform(im)\n",
        "        return im, y, p, img_name, cls_name\n",
        "\n",
        "test_ds = CSVTestDataset(test_root, test_csv, transform=to_tensor_norm, class_to_idx=class_to_idx)\n",
        "test_loader = DataLoader(test_ds, batch_size=64, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "# -----------------------------\n",
        "# VGG-19 (TorchVision)\n",
        "# -----------------------------\n",
        "def make_model(num_classes=8):\n",
        "    try:\n",
        "        weights = models.VGG19_Weights.IMAGENET1K_V1\n",
        "        net = models.vgg19(weights=weights)\n",
        "    except Exception:\n",
        "        net = models.vgg19(pretrained=True)\n",
        "    in_features = net.classifier[-1].in_features\n",
        "    net.classifier[-1] = nn.Linear(in_features, num_classes)\n",
        "    return net.to(device)\n",
        "\n",
        "# -----------------------------\n",
        "# Lion optimizer (inline, per paper)\n",
        "# -----------------------------\n",
        "class Lion(optim.Optimizer):\n",
        "    def __init__(self, params, lr=1e-4, betas=(0.9, 0.99), weight_decay=0.0):\n",
        "        defaults = dict(lr=lr, betas=betas, weight_decay=weight_decay)\n",
        "        super().__init__(params, defaults)\n",
        "    @torch.no_grad()\n",
        "    def step(self, closure=None):\n",
        "        loss = None\n",
        "        if closure is not None:\n",
        "            with torch.enable_grad():\n",
        "                loss = closure()\n",
        "        for group in self.param_groups:\n",
        "            lr = group['lr']; wd = group['weight_decay']; beta1, beta2 = group['betas']\n",
        "            for p in group['params']:\n",
        "                if p.grad is None: continue\n",
        "                g = p.grad\n",
        "                state = self.state[p]\n",
        "                if len(state) == 0:\n",
        "                    state['exp_avg'] = torch.zeros_like(p)\n",
        "                m = state['exp_avg']\n",
        "                if wd != 0:  # decoupled weight decay\n",
        "                    p.mul_(1 - lr * wd)\n",
        "                m.mul_(beta2).add_(g, alpha=1 - beta2)\n",
        "                p.add_(m.sign(), alpha=-lr)\n",
        "                m.mul_(beta1).add_(g, alpha=1 - beta1)\n",
        "        return loss\n",
        "\n",
        "# -----------------------------\n",
        "# Aida optimizer: dynamic import from official repo\n",
        "# -----------------------------\n",
        "def load_aida_class():\n",
        "    repo_url = \"https://github.com/guoqiang-x-zhang/AidaOptimizer\"\n",
        "    clone_dir = \"/content/AidaOptimizer\"\n",
        "    if not os.path.isdir(clone_dir):\n",
        "        subprocess.check_call([\"git\", \"clone\", \"--depth\", \"1\", repo_url, clone_dir])\n",
        "    # find a Python file that defines class Aida\n",
        "    def find_aida_py(root):\n",
        "        for p in pathlib.Path(root).rglob(\"*.py\"):\n",
        "            try:\n",
        "                txt = p.read_text(errors=\"ignore\")\n",
        "                if re.search(r\"class\\s+Aida\\b\", txt):\n",
        "                    return str(p)\n",
        "            except Exception:\n",
        "                pass\n",
        "        return None\n",
        "    aida_py = find_aida_py(clone_dir)\n",
        "    if aida_py is None:\n",
        "        raise ImportError(\"Aida class not found in the cloned repo.\")\n",
        "    spec = importlib.util.spec_from_file_location(\"aida_module\", aida_py)\n",
        "    aida_module = importlib.util.module_from_spec(spec)\n",
        "    spec.loader.exec_module(aida_module)\n",
        "    # try direct name\n",
        "    if hasattr(aida_module, \"Aida\"):\n",
        "        return aida_module.Aida\n",
        "    # fallback: search namespace\n",
        "    for name, obj in aida_module.__dict__.items():\n",
        "        if name.lower() == \"aida\" and isinstance(obj, type):\n",
        "            return obj\n",
        "    raise ImportError(\"Aida class symbol not exported.\")\n",
        "\n",
        "AidaOpt = load_aida_class()\n",
        "\n",
        "# -----------------------------\n",
        "# Optimizer Definitions\n",
        "# -----------------------------\n",
        "def make_optimizer(name, params, lr=1e-4, weight_decay=1e-4):\n",
        "    n = name.lower()\n",
        "    if n == \"adam\":\n",
        "        return optim.Adam(params, lr=lr, weight_decay=weight_decay)\n",
        "    if n == \"adamw\":\n",
        "        return optim.AdamW(params, lr=lr, weight_decay=weight_decay)\n",
        "    if n in (\"rmsprop\", \"rms\"):\n",
        "        return optim.RMSprop(params, lr=lr, weight_decay=weight_decay, momentum=0.9)\n",
        "    if n == \"lion\":\n",
        "        return Lion(params, lr=lr, weight_decay=weight_decay)\n",
        "    if n == \"aida\":\n",
        "        try:\n",
        "            return AidaOpt(params, lr=lr, weight_decay=weight_decay)\n",
        "        except TypeError:\n",
        "            return AidaOpt(params, lr=lr)\n",
        "    raise ValueError(f\"Unknown optimizer: {name}\")\n",
        "\n",
        "# -----------------------------\n",
        "# Train / Eval helpers\n",
        "# -----------------------------\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "#Softmax is applied to convert Raw Logits to Class Probabilities\n",
        "softmax  = nn.Softmax(dim=1)\n",
        "\n",
        "#Epoch Training Loop\n",
        "def train_one_epoch(model, loader, optimizer):\n",
        "    model.train()\n",
        "    total, correct = 0, 0\n",
        "    for x, y in loader:\n",
        "        x, y = x.to(device, non_blocking=True), y.to(device, non_blocking=True)\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        logits = model(x)\n",
        "        loss = criterion(logits, y)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        with torch.no_grad():\n",
        "            preds = logits.argmax(1)\n",
        "            correct += (preds == y).sum().item()\n",
        "            total   += y.size(0)\n",
        "    return correct/total  # train accuracy\n",
        "\n",
        "@torch.no_grad()\n",
        "def eval_model(model, loader):\n",
        "    model.eval()\n",
        "    total, correct = 0, 0\n",
        "    all_probs, all_preds, all_tgts, all_paths, all_names, all_cls = [], [], [], [], [], []\n",
        "    for batch in loader:\n",
        "        if len(batch) == 5:\n",
        "            x, y, paths, names, clsnames = batch\n",
        "        else:\n",
        "            x, y = batch; paths = [\"\"]*x.size(0); names = [\"\"]*x.size(0); clsnames = [\"\"]*x.size(0)\n",
        "        x = x.to(device, non_blocking=True); y = y.to(device, non_blocking=True)\n",
        "        #Per-sample probabilities Extraction\n",
        "        logits = model(x)\n",
        "        probs = softmax(logits)\n",
        "        preds = probs.argmax(1)\n",
        "        correct += (preds == y).sum().item(); total += y.size(0)\n",
        "        all_probs.append(probs.cpu()); all_preds.append(preds.cpu()); all_tgts.append(y.cpu())\n",
        "        all_paths.extend(list(paths)); all_names.extend(list(names)); all_cls.extend(list(clsnames))\n",
        "    all_probs = torch.cat(all_probs).numpy(); all_preds = torch.cat(all_preds).numpy(); all_tgts = torch.cat(all_tgts).numpy()\n",
        "    return (correct/total), all_probs, all_preds, all_tgts, all_paths, all_names, all_cls\n",
        "\n",
        "def format_acc_for_csv(x: float) -> float:\n",
        "    if x < 1.0:\n",
        "        return float(f\"{x:.3g}\") if x != 0 else 0.0\n",
        "    return float(f\"{x:.2f}\")\n",
        "\n",
        "def selective_metrics(probs_np, preds_np, tgts_np, tau=0.75):\n",
        "    maxc = probs_np.max(axis=1)\n",
        "    covered = maxc >= tau\n",
        "    coverage = covered.mean()\n",
        "    sel_acc = (preds_np[covered] == tgts_np[covered]).mean() if covered.sum()>0 else 0.0\n",
        "    hcer = ((preds_np != tgts_np) & (maxc >= tau)).mean()\n",
        "    return coverage, sel_acc, hcer\n",
        "\n",
        "def mccp(probs_np, preds_np, tgts_np):\n",
        "    mask = preds_np == tgts_np\n",
        "    return float(probs_np.max(axis=1)[mask].mean()) if mask.sum()>0 else 0.0\n",
        "\n",
        "def chcr_from_cm(cm, idx_to_class):\n",
        "    diag = np.diag(cm); n_per_class = cm.sum(axis=1)\n",
        "    full = [i for i,c in enumerate(diag) if c == n_per_class[i]]\n",
        "    if len(full) == len(diag): return \"all\"\n",
        "    if len(full) == len(diag)-1:\n",
        "        suffered = [i for i in range(len(diag)) if i not in full][0]\n",
        "        return f\"Exc {initials_of(idx_to_class[suffered])}({int(diag[suffered])})\"\n",
        "    maxc = diag.max()\n",
        "    winners = [i for i,c in enumerate(diag) if c == maxc]\n",
        "    return \", \".join(f\"{initials_of(idx_to_class[i])}({int(diag[i])})\" for i in winners)\n",
        "\n",
        "def save_confusion_matrix(cm, surname_ticks, save_path):\n",
        "    plt.figure(figsize=(6.5,5.6), dpi=160)\n",
        "    ax = sns.heatmap(cm, annot=True, fmt=\"d\", cbar=False)\n",
        "    ax.set_xlabel(\"Predicted\", fontweight=\"bold\")\n",
        "    ax.set_ylabel(\"Actual\",   fontweight=\"bold\")\n",
        "    ax.set_xticklabels(surname_ticks, rotation=45, ha=\"right\", fontweight=\"bold\")\n",
        "    ax.set_yticklabels(surname_ticks, rotation=0,   fontweight=\"bold\")\n",
        "    plt.tight_layout(); plt.savefig(save_path); plt.close()\n",
        "\n",
        "def save_confidence_face_image_random(paths, preds_np, tgts_np, probs_np, idx_to_class, save_path_png):\n",
        "    correct_idx = np.where(preds_np == tgts_np)[0]\n",
        "    if correct_idx.size == 0:\n",
        "        blank = np.zeros((224,224,3), dtype=np.uint8)\n",
        "        cv2.putText(blank, \"No correct face found\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
        "        cv2.imwrite(save_path_png, blank); return False\n",
        "    rng = np.random.default_rng()  # deliberately non-deterministic for variety\n",
        "    i = int(rng.choice(correct_idx))\n",
        "    path = paths[i]; pred = int(preds_np[i]); conf = float(probs_np[i, pred])\n",
        "    if not os.path.exists(path): return False\n",
        "    img = cv2.imread(path)\n",
        "    if img is None: return False\n",
        "    gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "    #haarcascade is A Pretrained face detector built on Haar-like features + cascade classifiers\n",
        "    face_cascade = cv2.CascadeClassifier(cv2.data.haarcascades + \"haarcascade_frontalface_default.xml\")\n",
        "    faces = face_cascade.detectMultiScale(gray, scaleFactor=1.1, minNeighbors=5, minSize=(40,40))\n",
        "    if len(faces) == 0:\n",
        "        h,w = img.shape[:2]; side = int(min(h,w)*0.35); x=(w-side)//2; y=(h-side)//2\n",
        "        faces = [(x,y,side,side)]\n",
        "    fx,fy,fw,fh = sorted(faces, key=lambda r: r[2]*r[3], reverse=True)[0]\n",
        "    cv2.rectangle(img, (fx,fy), (fx+fw,fy+fh), (0,255,0), 2)\n",
        "    surname = surname_of(idx_to_class[pred])\n",
        "    label = f\"{surname} {int(round(conf*100))}%\"\n",
        "    ty = max(fy-10, 20)\n",
        "    cv2.putText(img, label, (fx,ty), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0,255,0), 2, cv2.LINE_AA)\n",
        "    cv2.imwrite(save_path_png, img)\n",
        "    return True\n",
        "\n",
        "# Initialize metrics CSV\n",
        "if not os.path.exists(metrics_csv):\n",
        "    with open(metrics_csv, \"w\", newline=\"\") as f:\n",
        "        csv.writer(f).writerow(\n",
        "            [\"Optimizer\", \"Epochs\", \"Tr.A\", \"Te.A\", \"Cor.Cl\", \"CHCR\",\n",
        "             \"Coverage@0.75\", \"SelAcc@0.75\", \"HCER@0.75\", \"MCCP\"]\n",
        "        )\n",
        "\n",
        "# -----------------------------\n",
        "# Grid and constants\n",
        "# -----------------------------\n",
        "optimizers = [\"Adam\", \"AdamW\", \"RMSProp\", \"Lion\", \"Aida\"]\n",
        "epochs_grid = [5, 10, 20, 40, 60]\n",
        "LR = 1e-4\n",
        "WD = 1e-4\n",
        "TAU = 0.75\n",
        "\n",
        "for opt_name in optimizers:\n",
        "    for E in epochs_grid:\n",
        "        print(f\"\\n=== Run: {opt_name} for {E} epochs ===\")\n",
        "        model = make_model(num_classes=len(class_to_idx))\n",
        "        opt = make_optimizer(opt_name, model.parameters(), lr=LR, weight_decay=WD)\n",
        "\n",
        "        # ---- epoch loop: print Train/Test accuracy ----\n",
        "        for ep in range(1, E+1):\n",
        "            tr_acc = train_one_epoch(model, train_loader, opt)\n",
        "            te_acc, _, _, _, _, _, _ = eval_model(model, test_loader)\n",
        "            print(f\"Epoch {ep:>2}/{E}: Train Acc={tr_acc:.4f} | Test Acc={te_acc:.4f}\")\n",
        "\n",
        "        # ---- final evals for logging/plots ----\n",
        "        train_acc_eval, _, _, _, _, _, _ = eval_model(model, train_eval_loader)\n",
        "        test_acc, probs_np, preds_np, tgts_np, paths, names, cls_names = eval_model(model, test_loader)\n",
        "        correct_cls = int((preds_np == tgts_np).sum())\n",
        "\n",
        "        # Confusion matrix (surname axes, bold)\n",
        "        labels = list(range(len(class_to_idx)))\n",
        "        cm = confusion_matrix(tgts_np, preds_np, labels=labels)\n",
        "        cm_path = os.path.join(out_confmats, f\"{opt_name}_{E}.png\")\n",
        "        save_confusion_matrix(cm, surname_ticks, cm_path)\n",
        "\n",
        "        # Confidence image (random correct example, surname + %)\n",
        "        confimg_path = os.path.join(out_confimgs, f\"{opt_name}_{E}.png\")\n",
        "        # fix accidental '}' if path was pasted twice\n",
        "        if confimg_path.endswith(\"}\"): confimg_path = confimg_path[:-1]\n",
        "        ok = save_confidence_face_image_random(paths, preds_np, tgts_np, probs_np, idx_to_class, confimg_path)\n",
        "        if not ok:\n",
        "            blank = np.zeros((224,224,3), dtype=np.uint8)\n",
        "            cv2.putText(blank, \"No correct face found\", (10,120), cv2.FONT_HERSHEY_SIMPLEX, 0.6, (255,255,255), 1, cv2.LINE_AA)\n",
        "            cv2.imwrite(confimg_path, blank)\n",
        "\n",
        "        # Selective metrics & MCCP\n",
        "        coverage, sel_acc, hcer = selective_metrics(probs_np, preds_np, tgts_np, tau=TAU)\n",
        "        mccp_val = mccp(probs_np, preds_np, tgts_np)\n",
        "\n",
        "        # CHCR tag\n",
        "        chcr = chcr_from_cm(cm, idx_to_class)\n",
        "\n",
        "        # Rounding rules for Tr.A / Te.A\n",
        "        TrA = format_acc_for_csv(float(train_acc_eval))\n",
        "        TeA = format_acc_for_csv(float(test_acc))\n",
        "\n",
        "        with open(metrics_csv, \"a\", newline=\"\") as f:\n",
        "            csv.writer(f).writerow([\n",
        "                opt_name, E, TrA, TeA, correct_cls, chcr,\n",
        "                float(f\"{coverage:.4f}\"), float(f\"{sel_acc:.4f}\"), float(f\"{hcer:.4f}\"),\n",
        "                float(f\"{mccp_val:.4f}\")\n",
        "            ])\n",
        "\n",
        "print(\"\\nAll runs complete.\")\n",
        "print(f\"Confusion matrices -> {out_confmats}\")\n",
        "print(f\"Confidence images  -> {out_confimgs}\")\n",
        "print(f\"Metrics CSV        -> {metrics_csv}\")"
      ],
      "metadata": {
        "id": "sucY1Yt9NWpQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8b17473-4552-44d6-ca96-224c555f367f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "=== Run: Adam for 5 epochs ===\n",
            "Downloading: \"https://download.pytorch.org/models/vgg19-dcbb9e9d.pth\" to /root/.cache/torch/hub/checkpoints/vgg19-dcbb9e9d.pth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 548M/548M [00:02<00:00, 215MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/5: Train Acc=0.7725 | Test Acc=0.4792\n",
            "Epoch  2/5: Train Acc=0.9558 | Test Acc=0.5208\n",
            "Epoch  3/5: Train Acc=0.9779 | Test Acc=0.5083\n",
            "Epoch  4/5: Train Acc=0.9850 | Test Acc=0.5875\n",
            "Epoch  5/5: Train Acc=0.9933 | Test Acc=0.5208\n",
            "\n",
            "=== Run: Adam for 10 epochs ===\n",
            "Epoch  1/10: Train Acc=0.7792 | Test Acc=0.4667\n",
            "Epoch  2/10: Train Acc=0.9637 | Test Acc=0.6083\n",
            "Epoch  3/10: Train Acc=0.9871 | Test Acc=0.4958\n",
            "Epoch  4/10: Train Acc=0.9842 | Test Acc=0.5958\n",
            "Epoch  5/10: Train Acc=0.9854 | Test Acc=0.5958\n",
            "Epoch  6/10: Train Acc=0.9708 | Test Acc=0.5458\n",
            "Epoch  7/10: Train Acc=0.9833 | Test Acc=0.6000\n",
            "Epoch  8/10: Train Acc=0.9904 | Test Acc=0.6667\n",
            "Epoch  9/10: Train Acc=0.9988 | Test Acc=0.6917\n",
            "Epoch 10/10: Train Acc=1.0000 | Test Acc=0.6667\n",
            "\n",
            "=== Run: Adam for 20 epochs ===\n",
            "Epoch  1/20: Train Acc=0.8142 | Test Acc=0.4750\n",
            "Epoch  2/20: Train Acc=0.9808 | Test Acc=0.6625\n",
            "Epoch  3/20: Train Acc=0.9871 | Test Acc=0.6958\n",
            "Epoch  4/20: Train Acc=0.9679 | Test Acc=0.7625\n",
            "Epoch  5/20: Train Acc=0.9867 | Test Acc=0.5833\n",
            "Epoch  6/20: Train Acc=0.9846 | Test Acc=0.6917\n",
            "Epoch  7/20: Train Acc=0.9954 | Test Acc=0.6917\n",
            "Epoch  8/20: Train Acc=0.9983 | Test Acc=0.7417\n",
            "Epoch  9/20: Train Acc=0.9854 | Test Acc=0.5458\n",
            "Epoch 10/20: Train Acc=0.9783 | Test Acc=0.5917\n",
            "Epoch 11/20: Train Acc=0.9779 | Test Acc=0.7208\n",
            "Epoch 12/20: Train Acc=0.9967 | Test Acc=0.6333\n",
            "Epoch 13/20: Train Acc=0.9992 | Test Acc=0.6375\n",
            "Epoch 14/20: Train Acc=0.9988 | Test Acc=0.6917\n",
            "Epoch 15/20: Train Acc=0.9962 | Test Acc=0.7125\n",
            "Epoch 16/20: Train Acc=0.9983 | Test Acc=0.6833\n",
            "Epoch 17/20: Train Acc=1.0000 | Test Acc=0.7083\n",
            "Epoch 18/20: Train Acc=1.0000 | Test Acc=0.7042\n",
            "Epoch 19/20: Train Acc=1.0000 | Test Acc=0.7042\n",
            "Epoch 20/20: Train Acc=1.0000 | Test Acc=0.7000\n",
            "\n",
            "=== Run: Adam for 40 epochs ===\n",
            "Epoch  1/40: Train Acc=0.7738 | Test Acc=0.6042\n",
            "Epoch  2/40: Train Acc=0.9812 | Test Acc=0.5833\n",
            "Epoch  3/40: Train Acc=0.9817 | Test Acc=0.4042\n",
            "Epoch  4/40: Train Acc=0.9771 | Test Acc=0.6750\n",
            "Epoch  5/40: Train Acc=0.9771 | Test Acc=0.7833\n",
            "Epoch  6/40: Train Acc=0.9900 | Test Acc=0.7208\n",
            "Epoch  7/40: Train Acc=0.9871 | Test Acc=0.7458\n",
            "Epoch  8/40: Train Acc=0.9950 | Test Acc=0.7042\n",
            "Epoch  9/40: Train Acc=0.9933 | Test Acc=0.7292\n",
            "Epoch 10/40: Train Acc=1.0000 | Test Acc=0.7292\n",
            "Epoch 11/40: Train Acc=1.0000 | Test Acc=0.7292\n",
            "Epoch 12/40: Train Acc=1.0000 | Test Acc=0.7292\n",
            "Epoch 13/40: Train Acc=1.0000 | Test Acc=0.7333\n",
            "Epoch 14/40: Train Acc=1.0000 | Test Acc=0.7333\n",
            "Epoch 15/40: Train Acc=1.0000 | Test Acc=0.7333\n",
            "Epoch 16/40: Train Acc=1.0000 | Test Acc=0.7333\n",
            "Epoch 17/40: Train Acc=1.0000 | Test Acc=0.7375\n",
            "Epoch 18/40: Train Acc=1.0000 | Test Acc=0.7375\n",
            "Epoch 19/40: Train Acc=1.0000 | Test Acc=0.7375\n",
            "Epoch 20/40: Train Acc=1.0000 | Test Acc=0.7375\n",
            "Epoch 21/40: Train Acc=1.0000 | Test Acc=0.7375\n",
            "Epoch 22/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 23/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 24/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 25/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 26/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 27/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 28/40: Train Acc=1.0000 | Test Acc=0.7417\n",
            "Epoch 29/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 30/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 31/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 32/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 33/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 34/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 35/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 36/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 37/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 38/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 39/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "Epoch 40/40: Train Acc=1.0000 | Test Acc=0.7458\n",
            "\n",
            "=== Run: Adam for 60 epochs ===\n",
            "Epoch  1/60: Train Acc=0.8237 | Test Acc=0.6583\n",
            "Epoch  2/60: Train Acc=0.9754 | Test Acc=0.7292\n",
            "Epoch  3/60: Train Acc=0.9829 | Test Acc=0.6042\n",
            "Epoch  4/60: Train Acc=0.9833 | Test Acc=0.6583\n",
            "Epoch  5/60: Train Acc=0.9821 | Test Acc=0.4417\n",
            "Epoch  6/60: Train Acc=0.9888 | Test Acc=0.6375\n",
            "Epoch  7/60: Train Acc=0.9950 | Test Acc=0.6458\n",
            "Epoch  8/60: Train Acc=0.9946 | Test Acc=0.5958\n",
            "Epoch  9/60: Train Acc=0.9958 | Test Acc=0.6875\n",
            "Epoch 10/60: Train Acc=0.9946 | Test Acc=0.5958\n",
            "Epoch 11/60: Train Acc=0.9671 | Test Acc=0.5292\n",
            "Epoch 12/60: Train Acc=0.9867 | Test Acc=0.6542\n",
            "Epoch 13/60: Train Acc=0.9942 | Test Acc=0.5542\n",
            "Epoch 14/60: Train Acc=0.9938 | Test Acc=0.5583\n",
            "Epoch 15/60: Train Acc=0.9979 | Test Acc=0.6208\n",
            "Epoch 16/60: Train Acc=0.9996 | Test Acc=0.5292\n",
            "Epoch 17/60: Train Acc=1.0000 | Test Acc=0.6542\n",
            "Epoch 18/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 19/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 20/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 21/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 22/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 23/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 24/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 25/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 26/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 27/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 28/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 29/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 30/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 31/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 32/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 33/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 34/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 35/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 36/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 37/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 38/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 39/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 40/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 41/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 42/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 43/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 44/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 45/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 46/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 47/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 48/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 49/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 50/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 51/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 52/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 53/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 54/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 55/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 56/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 57/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 58/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 59/60: Train Acc=1.0000 | Test Acc=0.6667\n",
            "Epoch 60/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "\n",
            "=== Run: AdamW for 5 epochs ===\n",
            "Epoch  1/5: Train Acc=0.7896 | Test Acc=0.7208\n",
            "Epoch  2/5: Train Acc=0.9779 | Test Acc=0.5375\n",
            "Epoch  3/5: Train Acc=0.9833 | Test Acc=0.6375\n",
            "Epoch  4/5: Train Acc=0.9671 | Test Acc=0.6708\n",
            "Epoch  5/5: Train Acc=0.9962 | Test Acc=0.7125\n",
            "\n",
            "=== Run: AdamW for 10 epochs ===\n",
            "Epoch  1/10: Train Acc=0.7983 | Test Acc=0.5167\n",
            "Epoch  2/10: Train Acc=0.9762 | Test Acc=0.7417\n",
            "Epoch  3/10: Train Acc=0.9679 | Test Acc=0.5333\n",
            "Epoch  4/10: Train Acc=0.9871 | Test Acc=0.7208\n",
            "Epoch  5/10: Train Acc=0.9904 | Test Acc=0.6417\n",
            "Epoch  6/10: Train Acc=0.9933 | Test Acc=0.6208\n",
            "Epoch  7/10: Train Acc=0.9971 | Test Acc=0.7208\n",
            "Epoch  8/10: Train Acc=0.9800 | Test Acc=0.6542\n",
            "Epoch  9/10: Train Acc=0.9738 | Test Acc=0.5250\n",
            "Epoch 10/10: Train Acc=0.9854 | Test Acc=0.5208\n",
            "\n",
            "=== Run: AdamW for 20 epochs ===\n",
            "Epoch  1/20: Train Acc=0.8137 | Test Acc=0.5875\n",
            "Epoch  2/20: Train Acc=0.9675 | Test Acc=0.4292\n",
            "Epoch  3/20: Train Acc=0.9829 | Test Acc=0.6458\n",
            "Epoch  4/20: Train Acc=0.9958 | Test Acc=0.6208\n",
            "Epoch  5/20: Train Acc=0.9854 | Test Acc=0.5667\n",
            "Epoch  6/20: Train Acc=0.9858 | Test Acc=0.6417\n",
            "Epoch  7/20: Train Acc=0.9771 | Test Acc=0.5875\n",
            "Epoch  8/20: Train Acc=0.9825 | Test Acc=0.6208\n",
            "Epoch  9/20: Train Acc=0.9996 | Test Acc=0.6750\n",
            "Epoch 10/20: Train Acc=1.0000 | Test Acc=0.6917\n",
            "Epoch 11/20: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 12/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 13/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 14/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 15/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 16/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 17/20: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 18/20: Train Acc=1.0000 | Test Acc=0.6917\n",
            "Epoch 19/20: Train Acc=1.0000 | Test Acc=0.6917\n",
            "Epoch 20/20: Train Acc=1.0000 | Test Acc=0.6917\n",
            "\n",
            "=== Run: AdamW for 40 epochs ===\n",
            "Epoch  1/40: Train Acc=0.8037 | Test Acc=0.4250\n",
            "Epoch  2/40: Train Acc=0.9542 | Test Acc=0.6958\n",
            "Epoch  3/40: Train Acc=0.9804 | Test Acc=0.7042\n",
            "Epoch  4/40: Train Acc=0.9862 | Test Acc=0.5708\n",
            "Epoch  5/40: Train Acc=0.9862 | Test Acc=0.6458\n",
            "Epoch  6/40: Train Acc=0.9933 | Test Acc=0.6292\n",
            "Epoch  7/40: Train Acc=0.9967 | Test Acc=0.5875\n",
            "Epoch  8/40: Train Acc=0.9817 | Test Acc=0.5208\n",
            "Epoch  9/40: Train Acc=0.9862 | Test Acc=0.6333\n",
            "Epoch 10/40: Train Acc=0.9967 | Test Acc=0.6792\n",
            "Epoch 11/40: Train Acc=0.9992 | Test Acc=0.7125\n",
            "Epoch 12/40: Train Acc=0.9988 | Test Acc=0.6708\n",
            "Epoch 13/40: Train Acc=0.9896 | Test Acc=0.5750\n",
            "Epoch 14/40: Train Acc=0.9767 | Test Acc=0.4875\n",
            "Epoch 15/40: Train Acc=0.9942 | Test Acc=0.6875\n",
            "Epoch 16/40: Train Acc=0.9729 | Test Acc=0.5625\n",
            "Epoch 17/40: Train Acc=0.9992 | Test Acc=0.5875\n",
            "Epoch 18/40: Train Acc=1.0000 | Test Acc=0.6000\n",
            "Epoch 19/40: Train Acc=1.0000 | Test Acc=0.6042\n",
            "Epoch 20/40: Train Acc=1.0000 | Test Acc=0.6083\n",
            "Epoch 21/40: Train Acc=1.0000 | Test Acc=0.6208\n",
            "Epoch 22/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 23/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 24/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 25/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 26/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 27/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 28/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 29/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 30/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 31/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 32/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 33/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 34/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 35/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 36/40: Train Acc=1.0000 | Test Acc=0.6375\n",
            "Epoch 37/40: Train Acc=1.0000 | Test Acc=0.6417\n",
            "Epoch 38/40: Train Acc=1.0000 | Test Acc=0.6458\n",
            "Epoch 39/40: Train Acc=1.0000 | Test Acc=0.6458\n",
            "Epoch 40/40: Train Acc=1.0000 | Test Acc=0.6500\n",
            "\n",
            "=== Run: AdamW for 60 epochs ===\n",
            "Epoch  1/60: Train Acc=0.8183 | Test Acc=0.6083\n",
            "Epoch  2/60: Train Acc=0.9629 | Test Acc=0.6958\n",
            "Epoch  3/60: Train Acc=0.9792 | Test Acc=0.4917\n",
            "Epoch  4/60: Train Acc=0.9871 | Test Acc=0.4750\n",
            "Epoch  5/60: Train Acc=0.9971 | Test Acc=0.6292\n",
            "Epoch  6/60: Train Acc=0.9912 | Test Acc=0.6417\n",
            "Epoch  7/60: Train Acc=0.9708 | Test Acc=0.6750\n",
            "Epoch  8/60: Train Acc=0.9850 | Test Acc=0.5708\n",
            "Epoch  9/60: Train Acc=0.9829 | Test Acc=0.5833\n",
            "Epoch 10/60: Train Acc=0.9933 | Test Acc=0.6083\n",
            "Epoch 11/60: Train Acc=0.9996 | Test Acc=0.6625\n",
            "Epoch 12/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 13/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 14/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 15/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 16/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 17/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 18/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 19/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 20/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 21/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 22/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 23/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 24/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 25/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 26/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 27/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 28/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 29/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 30/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 31/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 32/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 33/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 34/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 35/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 36/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 37/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 38/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 39/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 40/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 41/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 42/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 43/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 44/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 45/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 46/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 47/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 48/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 49/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 50/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 51/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 52/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 53/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 54/60: Train Acc=1.0000 | Test Acc=0.6583\n",
            "Epoch 55/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 56/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 57/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 58/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 59/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 60/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "\n",
            "=== Run: RMSProp for 5 epochs ===\n",
            "Epoch  1/5: Train Acc=0.1358 | Test Acc=0.1333\n",
            "Epoch  2/5: Train Acc=0.1304 | Test Acc=0.1250\n",
            "Epoch  3/5: Train Acc=0.1421 | Test Acc=0.1083\n",
            "Epoch  4/5: Train Acc=0.1392 | Test Acc=0.1667\n",
            "Epoch  5/5: Train Acc=0.1521 | Test Acc=0.1667\n",
            "\n",
            "=== Run: RMSProp for 10 epochs ===\n",
            "Epoch  1/10: Train Acc=0.1321 | Test Acc=0.1250\n",
            "Epoch  2/10: Train Acc=0.1233 | Test Acc=0.1958\n",
            "Epoch  3/10: Train Acc=0.1263 | Test Acc=0.1250\n",
            "Epoch  4/10: Train Acc=0.1242 | Test Acc=0.1292\n",
            "Epoch  5/10: Train Acc=0.1467 | Test Acc=0.1167\n",
            "Epoch  6/10: Train Acc=0.1617 | Test Acc=0.2083\n",
            "Epoch  7/10: Train Acc=0.1554 | Test Acc=0.1250\n",
            "Epoch  8/10: Train Acc=0.1371 | Test Acc=0.1333\n",
            "Epoch  9/10: Train Acc=0.1358 | Test Acc=0.1667\n",
            "Epoch 10/10: Train Acc=0.1487 | Test Acc=0.1042\n",
            "\n",
            "=== Run: RMSProp for 20 epochs ===\n",
            "Epoch  1/20: Train Acc=0.1392 | Test Acc=0.1250\n",
            "Epoch  2/20: Train Acc=0.1229 | Test Acc=0.1250\n",
            "Epoch  3/20: Train Acc=0.1333 | Test Acc=0.1250\n",
            "Epoch  4/20: Train Acc=0.2188 | Test Acc=0.1375\n",
            "Epoch  5/20: Train Acc=0.1696 | Test Acc=0.1167\n",
            "Epoch  6/20: Train Acc=0.1975 | Test Acc=0.1083\n",
            "Epoch  7/20: Train Acc=0.2692 | Test Acc=0.1250\n",
            "Epoch  8/20: Train Acc=0.3946 | Test Acc=0.1833\n",
            "Epoch  9/20: Train Acc=0.5175 | Test Acc=0.1417\n",
            "Epoch 10/20: Train Acc=0.6763 | Test Acc=0.1375\n",
            "Epoch 11/20: Train Acc=0.7746 | Test Acc=0.1833\n",
            "Epoch 12/20: Train Acc=0.7442 | Test Acc=0.1667\n",
            "Epoch 13/20: Train Acc=0.7963 | Test Acc=0.2167\n",
            "Epoch 14/20: Train Acc=0.8254 | Test Acc=0.2250\n",
            "Epoch 15/20: Train Acc=0.8454 | Test Acc=0.2083\n",
            "Epoch 16/20: Train Acc=0.8533 | Test Acc=0.1417\n",
            "Epoch 17/20: Train Acc=0.8662 | Test Acc=0.1917\n",
            "Epoch 18/20: Train Acc=0.8675 | Test Acc=0.1875\n",
            "Epoch 19/20: Train Acc=0.8788 | Test Acc=0.2333\n",
            "Epoch 20/20: Train Acc=0.9021 | Test Acc=0.1792\n",
            "\n",
            "=== Run: RMSProp for 40 epochs ===\n",
            "Epoch  1/40: Train Acc=0.1254 | Test Acc=0.1250\n",
            "Epoch  2/40: Train Acc=0.1658 | Test Acc=0.1917\n",
            "Epoch  3/40: Train Acc=0.2579 | Test Acc=0.2125\n",
            "Epoch  4/40: Train Acc=0.3075 | Test Acc=0.1625\n",
            "Epoch  5/40: Train Acc=0.3754 | Test Acc=0.1958\n",
            "Epoch  6/40: Train Acc=0.5450 | Test Acc=0.1792\n",
            "Epoch  7/40: Train Acc=0.7021 | Test Acc=0.2167\n",
            "Epoch  8/40: Train Acc=0.5571 | Test Acc=0.1750\n",
            "Epoch  9/40: Train Acc=0.6488 | Test Acc=0.1833\n",
            "Epoch 10/40: Train Acc=0.7646 | Test Acc=0.1875\n",
            "Epoch 11/40: Train Acc=0.7896 | Test Acc=0.2458\n",
            "Epoch 12/40: Train Acc=0.8200 | Test Acc=0.2208\n",
            "Epoch 13/40: Train Acc=0.8392 | Test Acc=0.1917\n",
            "Epoch 14/40: Train Acc=0.8129 | Test Acc=0.1625\n",
            "Epoch 15/40: Train Acc=0.7762 | Test Acc=0.2000\n",
            "Epoch 16/40: Train Acc=0.8538 | Test Acc=0.2458\n",
            "Epoch 17/40: Train Acc=0.8838 | Test Acc=0.2292\n",
            "Epoch 18/40: Train Acc=0.8879 | Test Acc=0.2458\n",
            "Epoch 19/40: Train Acc=0.8900 | Test Acc=0.2208\n",
            "Epoch 20/40: Train Acc=0.8796 | Test Acc=0.1583\n",
            "Epoch 21/40: Train Acc=0.8867 | Test Acc=0.2083\n",
            "Epoch 22/40: Train Acc=0.9208 | Test Acc=0.1708\n",
            "Epoch 23/40: Train Acc=0.9117 | Test Acc=0.1958\n",
            "Epoch 24/40: Train Acc=0.8013 | Test Acc=0.0833\n",
            "Epoch 25/40: Train Acc=0.1358 | Test Acc=0.1250\n",
            "Epoch 26/40: Train Acc=0.1208 | Test Acc=0.1292\n",
            "Epoch 27/40: Train Acc=0.2442 | Test Acc=0.1833\n",
            "Epoch 28/40: Train Acc=0.5467 | Test Acc=0.1833\n",
            "Epoch 29/40: Train Acc=0.7171 | Test Acc=0.1750\n",
            "Epoch 30/40: Train Acc=0.8304 | Test Acc=0.2125\n",
            "Epoch 31/40: Train Acc=0.8671 | Test Acc=0.1958\n",
            "Epoch 32/40: Train Acc=0.8696 | Test Acc=0.2125\n",
            "Epoch 33/40: Train Acc=0.9067 | Test Acc=0.2000\n",
            "Epoch 34/40: Train Acc=0.8612 | Test Acc=0.2167\n",
            "Epoch 35/40: Train Acc=0.8592 | Test Acc=0.1875\n",
            "Epoch 36/40: Train Acc=0.9108 | Test Acc=0.1833\n",
            "Epoch 37/40: Train Acc=0.9200 | Test Acc=0.2250\n",
            "Epoch 38/40: Train Acc=0.9329 | Test Acc=0.1500\n",
            "Epoch 39/40: Train Acc=0.8950 | Test Acc=0.1833\n",
            "Epoch 40/40: Train Acc=0.9496 | Test Acc=0.1875\n",
            "\n",
            "=== Run: RMSProp for 60 epochs ===\n",
            "Epoch  1/60: Train Acc=0.1225 | Test Acc=0.1667\n",
            "Epoch  2/60: Train Acc=0.1433 | Test Acc=0.2083\n",
            "Epoch  3/60: Train Acc=0.1379 | Test Acc=0.1208\n",
            "Epoch  4/60: Train Acc=0.1525 | Test Acc=0.1375\n",
            "Epoch  5/60: Train Acc=0.1342 | Test Acc=0.1250\n",
            "Epoch  6/60: Train Acc=0.1633 | Test Acc=0.1792\n",
            "Epoch  7/60: Train Acc=0.1638 | Test Acc=0.1375\n",
            "Epoch  8/60: Train Acc=0.1733 | Test Acc=0.1583\n",
            "Epoch  9/60: Train Acc=0.1717 | Test Acc=0.1583\n",
            "Epoch 10/60: Train Acc=0.2008 | Test Acc=0.1250\n",
            "Epoch 11/60: Train Acc=0.1679 | Test Acc=0.2375\n",
            "Epoch 12/60: Train Acc=0.2008 | Test Acc=0.2583\n",
            "Epoch 13/60: Train Acc=0.1471 | Test Acc=0.1250\n",
            "Epoch 14/60: Train Acc=0.1317 | Test Acc=0.1250\n",
            "Epoch 15/60: Train Acc=0.1683 | Test Acc=0.1583\n",
            "Epoch 16/60: Train Acc=0.2792 | Test Acc=0.2250\n",
            "Epoch 17/60: Train Acc=0.3979 | Test Acc=0.2333\n",
            "Epoch 18/60: Train Acc=0.5508 | Test Acc=0.2250\n",
            "Epoch 19/60: Train Acc=0.6433 | Test Acc=0.2500\n",
            "Epoch 20/60: Train Acc=0.7092 | Test Acc=0.2708\n",
            "Epoch 21/60: Train Acc=0.7471 | Test Acc=0.2583\n",
            "Epoch 22/60: Train Acc=0.7492 | Test Acc=0.2208\n",
            "Epoch 23/60: Train Acc=0.7967 | Test Acc=0.2333\n",
            "Epoch 24/60: Train Acc=0.8208 | Test Acc=0.2375\n",
            "Epoch 25/60: Train Acc=0.8396 | Test Acc=0.2083\n",
            "Epoch 26/60: Train Acc=0.8300 | Test Acc=0.3083\n",
            "Epoch 27/60: Train Acc=0.8696 | Test Acc=0.2500\n",
            "Epoch 28/60: Train Acc=0.8137 | Test Acc=0.2250\n",
            "Epoch 29/60: Train Acc=0.8842 | Test Acc=0.2750\n",
            "Epoch 30/60: Train Acc=0.9125 | Test Acc=0.3333\n",
            "Epoch 31/60: Train Acc=0.8871 | Test Acc=0.3042\n",
            "Epoch 32/60: Train Acc=0.9033 | Test Acc=0.3250\n",
            "Epoch 33/60: Train Acc=0.8792 | Test Acc=0.2417\n",
            "Epoch 34/60: Train Acc=0.8838 | Test Acc=0.2833\n",
            "Epoch 35/60: Train Acc=0.8879 | Test Acc=0.2792\n",
            "Epoch 36/60: Train Acc=0.9158 | Test Acc=0.3125\n",
            "Epoch 37/60: Train Acc=0.8825 | Test Acc=0.3042\n",
            "Epoch 38/60: Train Acc=0.9279 | Test Acc=0.2250\n",
            "Epoch 39/60: Train Acc=0.9304 | Test Acc=0.2542\n",
            "Epoch 40/60: Train Acc=0.9537 | Test Acc=0.2917\n",
            "Epoch 41/60: Train Acc=0.9263 | Test Acc=0.2542\n",
            "Epoch 42/60: Train Acc=0.9163 | Test Acc=0.2250\n",
            "Epoch 43/60: Train Acc=0.9217 | Test Acc=0.2583\n",
            "Epoch 44/60: Train Acc=0.9175 | Test Acc=0.2667\n",
            "Epoch 45/60: Train Acc=0.9433 | Test Acc=0.2208\n",
            "Epoch 46/60: Train Acc=0.9308 | Test Acc=0.2625\n",
            "Epoch 47/60: Train Acc=0.9125 | Test Acc=0.3000\n",
            "Epoch 48/60: Train Acc=0.9038 | Test Acc=0.2458\n",
            "Epoch 49/60: Train Acc=0.9233 | Test Acc=0.2833\n",
            "Epoch 50/60: Train Acc=0.9542 | Test Acc=0.2583\n",
            "Epoch 51/60: Train Acc=0.9217 | Test Acc=0.3083\n",
            "Epoch 52/60: Train Acc=0.9363 | Test Acc=0.2250\n",
            "Epoch 53/60: Train Acc=0.9383 | Test Acc=0.2333\n",
            "Epoch 54/60: Train Acc=0.9425 | Test Acc=0.2375\n",
            "Epoch 55/60: Train Acc=0.9463 | Test Acc=0.2625\n",
            "Epoch 56/60: Train Acc=0.9625 | Test Acc=0.2542\n",
            "Epoch 57/60: Train Acc=0.9563 | Test Acc=0.2667\n",
            "Epoch 58/60: Train Acc=0.9500 | Test Acc=0.2042\n",
            "Epoch 59/60: Train Acc=0.9442 | Test Acc=0.2583\n",
            "Epoch 60/60: Train Acc=0.9413 | Test Acc=0.2583\n",
            "\n",
            "=== Run: Lion for 5 epochs ===\n",
            "Epoch  1/5: Train Acc=0.1537 | Test Acc=0.1167\n",
            "Epoch  2/5: Train Acc=0.2117 | Test Acc=0.2333\n",
            "Epoch  3/5: Train Acc=0.4175 | Test Acc=0.2083\n",
            "Epoch  4/5: Train Acc=0.5575 | Test Acc=0.2250\n",
            "Epoch  5/5: Train Acc=0.6792 | Test Acc=0.2458\n",
            "\n",
            "=== Run: Lion for 10 epochs ===\n",
            "Epoch  1/10: Train Acc=0.1646 | Test Acc=0.1250\n",
            "Epoch  2/10: Train Acc=0.2129 | Test Acc=0.1792\n",
            "Epoch  3/10: Train Acc=0.3729 | Test Acc=0.1542\n",
            "Epoch  4/10: Train Acc=0.5346 | Test Acc=0.2583\n",
            "Epoch  5/10: Train Acc=0.6808 | Test Acc=0.2917\n",
            "Epoch  6/10: Train Acc=0.7883 | Test Acc=0.2208\n",
            "Epoch  7/10: Train Acc=0.8608 | Test Acc=0.2708\n",
            "Epoch  8/10: Train Acc=0.8962 | Test Acc=0.2417\n",
            "Epoch  9/10: Train Acc=0.9154 | Test Acc=0.1917\n",
            "Epoch 10/10: Train Acc=0.9383 | Test Acc=0.2625\n",
            "\n",
            "=== Run: Lion for 20 epochs ===\n",
            "Epoch  1/20: Train Acc=0.1554 | Test Acc=0.1250\n",
            "Epoch  2/20: Train Acc=0.1812 | Test Acc=0.1458\n",
            "Epoch  3/20: Train Acc=0.3875 | Test Acc=0.1792\n",
            "Epoch  4/20: Train Acc=0.5587 | Test Acc=0.2500\n",
            "Epoch  5/20: Train Acc=0.6750 | Test Acc=0.1917\n",
            "Epoch  6/20: Train Acc=0.7779 | Test Acc=0.2583\n",
            "Epoch  7/20: Train Acc=0.8342 | Test Acc=0.2458\n",
            "Epoch  8/20: Train Acc=0.8458 | Test Acc=0.2917\n",
            "Epoch  9/20: Train Acc=0.9183 | Test Acc=0.2667\n",
            "Epoch 10/20: Train Acc=0.9300 | Test Acc=0.2667\n",
            "Epoch 11/20: Train Acc=0.9387 | Test Acc=0.3083\n",
            "Epoch 12/20: Train Acc=0.9492 | Test Acc=0.3375\n",
            "Epoch 13/20: Train Acc=0.9567 | Test Acc=0.3583\n",
            "Epoch 14/20: Train Acc=0.9517 | Test Acc=0.3292\n",
            "Epoch 15/20: Train Acc=0.9463 | Test Acc=0.2542\n",
            "Epoch 16/20: Train Acc=0.9696 | Test Acc=0.3250\n",
            "Epoch 17/20: Train Acc=0.9733 | Test Acc=0.3458\n",
            "Epoch 18/20: Train Acc=0.9567 | Test Acc=0.3375\n",
            "Epoch 19/20: Train Acc=0.9688 | Test Acc=0.3333\n",
            "Epoch 20/20: Train Acc=0.9592 | Test Acc=0.3250\n",
            "\n",
            "=== Run: Lion for 40 epochs ===\n",
            "Epoch  1/40: Train Acc=0.1458 | Test Acc=0.1250\n",
            "Epoch  2/40: Train Acc=0.1817 | Test Acc=0.1792\n",
            "Epoch  3/40: Train Acc=0.3217 | Test Acc=0.1417\n",
            "Epoch  4/40: Train Acc=0.4921 | Test Acc=0.2500\n",
            "Epoch  5/40: Train Acc=0.6254 | Test Acc=0.2292\n",
            "Epoch  6/40: Train Acc=0.7163 | Test Acc=0.1958\n",
            "Epoch  7/40: Train Acc=0.8329 | Test Acc=0.2417\n",
            "Epoch  8/40: Train Acc=0.8671 | Test Acc=0.2708\n",
            "Epoch  9/40: Train Acc=0.9096 | Test Acc=0.2500\n",
            "Epoch 10/40: Train Acc=0.9125 | Test Acc=0.2500\n",
            "Epoch 11/40: Train Acc=0.9363 | Test Acc=0.3083\n",
            "Epoch 12/40: Train Acc=0.9496 | Test Acc=0.2500\n",
            "Epoch 13/40: Train Acc=0.9454 | Test Acc=0.3458\n",
            "Epoch 14/40: Train Acc=0.9471 | Test Acc=0.3083\n",
            "Epoch 15/40: Train Acc=0.9629 | Test Acc=0.2250\n",
            "Epoch 16/40: Train Acc=0.9704 | Test Acc=0.2750\n",
            "Epoch 17/40: Train Acc=0.9729 | Test Acc=0.2583\n",
            "Epoch 18/40: Train Acc=0.9717 | Test Acc=0.2500\n",
            "Epoch 19/40: Train Acc=0.9604 | Test Acc=0.2625\n",
            "Epoch 20/40: Train Acc=0.9767 | Test Acc=0.2375\n",
            "Epoch 21/40: Train Acc=0.9742 | Test Acc=0.2417\n",
            "Epoch 22/40: Train Acc=0.9654 | Test Acc=0.2208\n",
            "Epoch 23/40: Train Acc=0.9642 | Test Acc=0.2667\n",
            "Epoch 24/40: Train Acc=0.9671 | Test Acc=0.2167\n",
            "Epoch 25/40: Train Acc=0.9738 | Test Acc=0.2625\n",
            "Epoch 26/40: Train Acc=0.9529 | Test Acc=0.2625\n",
            "Epoch 27/40: Train Acc=0.9613 | Test Acc=0.2167\n",
            "Epoch 28/40: Train Acc=0.9725 | Test Acc=0.3083\n",
            "Epoch 29/40: Train Acc=0.9717 | Test Acc=0.2667\n",
            "Epoch 30/40: Train Acc=0.9788 | Test Acc=0.2375\n",
            "Epoch 31/40: Train Acc=0.9679 | Test Acc=0.2625\n",
            "Epoch 32/40: Train Acc=0.9738 | Test Acc=0.2375\n",
            "Epoch 33/40: Train Acc=0.9812 | Test Acc=0.2500\n",
            "Epoch 34/40: Train Acc=0.9750 | Test Acc=0.2333\n",
            "Epoch 35/40: Train Acc=0.9771 | Test Acc=0.2042\n",
            "Epoch 36/40: Train Acc=0.9600 | Test Acc=0.2875\n",
            "Epoch 37/40: Train Acc=0.9742 | Test Acc=0.2250\n",
            "Epoch 38/40: Train Acc=0.9617 | Test Acc=0.2292\n",
            "Epoch 39/40: Train Acc=0.9567 | Test Acc=0.3000\n",
            "Epoch 40/40: Train Acc=0.9458 | Test Acc=0.2542\n",
            "\n",
            "=== Run: Lion for 60 epochs ===\n",
            "Epoch  1/60: Train Acc=0.1417 | Test Acc=0.1292\n",
            "Epoch  2/60: Train Acc=0.1667 | Test Acc=0.1625\n",
            "Epoch  3/60: Train Acc=0.2371 | Test Acc=0.1792\n",
            "Epoch  4/60: Train Acc=0.3492 | Test Acc=0.1167\n",
            "Epoch  5/60: Train Acc=0.5183 | Test Acc=0.1458\n",
            "Epoch  6/60: Train Acc=0.6646 | Test Acc=0.1542\n",
            "Epoch  7/60: Train Acc=0.7800 | Test Acc=0.2125\n",
            "Epoch  8/60: Train Acc=0.8254 | Test Acc=0.2250\n",
            "Epoch  9/60: Train Acc=0.8633 | Test Acc=0.2292\n",
            "Epoch 10/60: Train Acc=0.8962 | Test Acc=0.2417\n",
            "Epoch 11/60: Train Acc=0.9329 | Test Acc=0.2500\n",
            "Epoch 12/60: Train Acc=0.9317 | Test Acc=0.2167\n",
            "Epoch 13/60: Train Acc=0.9287 | Test Acc=0.2583\n",
            "Epoch 14/60: Train Acc=0.9492 | Test Acc=0.2500\n",
            "Epoch 15/60: Train Acc=0.9600 | Test Acc=0.1750\n",
            "Epoch 16/60: Train Acc=0.9537 | Test Acc=0.2708\n",
            "Epoch 17/60: Train Acc=0.9642 | Test Acc=0.2375\n",
            "Epoch 18/60: Train Acc=0.9633 | Test Acc=0.2667\n",
            "Epoch 19/60: Train Acc=0.9733 | Test Acc=0.2333\n",
            "Epoch 20/60: Train Acc=0.9583 | Test Acc=0.2458\n",
            "Epoch 21/60: Train Acc=0.9688 | Test Acc=0.2333\n",
            "Epoch 22/60: Train Acc=0.9704 | Test Acc=0.2792\n",
            "Epoch 23/60: Train Acc=0.9742 | Test Acc=0.2125\n",
            "Epoch 24/60: Train Acc=0.9692 | Test Acc=0.2542\n",
            "Epoch 25/60: Train Acc=0.9742 | Test Acc=0.2208\n",
            "Epoch 26/60: Train Acc=0.9796 | Test Acc=0.2333\n",
            "Epoch 27/60: Train Acc=0.9804 | Test Acc=0.2292\n",
            "Epoch 28/60: Train Acc=0.9671 | Test Acc=0.2208\n",
            "Epoch 29/60: Train Acc=0.9800 | Test Acc=0.2417\n",
            "Epoch 30/60: Train Acc=0.9767 | Test Acc=0.1833\n",
            "Epoch 31/60: Train Acc=0.9783 | Test Acc=0.2375\n",
            "Epoch 32/60: Train Acc=0.9779 | Test Acc=0.2792\n",
            "Epoch 33/60: Train Acc=0.9738 | Test Acc=0.2208\n",
            "Epoch 34/60: Train Acc=0.9650 | Test Acc=0.2083\n",
            "Epoch 35/60: Train Acc=0.9692 | Test Acc=0.2208\n",
            "Epoch 36/60: Train Acc=0.9771 | Test Acc=0.2458\n",
            "Epoch 37/60: Train Acc=0.9683 | Test Acc=0.2208\n",
            "Epoch 38/60: Train Acc=0.9700 | Test Acc=0.2833\n",
            "Epoch 39/60: Train Acc=0.9754 | Test Acc=0.2375\n",
            "Epoch 40/60: Train Acc=0.9746 | Test Acc=0.1750\n",
            "Epoch 41/60: Train Acc=0.9758 | Test Acc=0.1917\n",
            "Epoch 42/60: Train Acc=0.9783 | Test Acc=0.2083\n",
            "Epoch 43/60: Train Acc=0.9808 | Test Acc=0.2208\n",
            "Epoch 44/60: Train Acc=0.9838 | Test Acc=0.2083\n",
            "Epoch 45/60: Train Acc=0.9792 | Test Acc=0.2875\n",
            "Epoch 46/60: Train Acc=0.9821 | Test Acc=0.3083\n",
            "Epoch 47/60: Train Acc=0.9817 | Test Acc=0.2500\n",
            "Epoch 48/60: Train Acc=0.9738 | Test Acc=0.2375\n",
            "Epoch 49/60: Train Acc=0.9679 | Test Acc=0.2583\n",
            "Epoch 50/60: Train Acc=0.9808 | Test Acc=0.2292\n",
            "Epoch 51/60: Train Acc=0.9842 | Test Acc=0.1917\n",
            "Epoch 52/60: Train Acc=0.9829 | Test Acc=0.2250\n",
            "Epoch 53/60: Train Acc=0.8983 | Test Acc=0.2042\n",
            "Epoch 54/60: Train Acc=0.9321 | Test Acc=0.1667\n",
            "Epoch 55/60: Train Acc=0.9379 | Test Acc=0.1750\n",
            "Epoch 56/60: Train Acc=0.9583 | Test Acc=0.1917\n",
            "Epoch 57/60: Train Acc=0.9583 | Test Acc=0.2417\n",
            "Epoch 58/60: Train Acc=0.9783 | Test Acc=0.2208\n",
            "Epoch 59/60: Train Acc=0.9729 | Test Acc=0.2167\n",
            "Epoch 60/60: Train Acc=0.8888 | Test Acc=0.2125\n",
            "\n",
            "=== Run: Aida for 5 epochs ===\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/content/AidaOptimizer/NLP_Transformer/Aida.py:106: UserWarning: This overload of add_ is deprecated:\n",
            "\tadd_(Number alpha, Tensor other)\n",
            "Consider using one of the following signatures instead:\n",
            "\tadd_(Tensor other, *, Number alpha = 1) (Triggered internally at /pytorch/torch/csrc/utils/python_arg_parser.cpp:1691.)\n",
            "  grad.add_(group['weight_decay'], p.data)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch  1/5: Train Acc=0.7467 | Test Acc=0.6083\n",
            "Epoch  2/5: Train Acc=0.9733 | Test Acc=0.4708\n",
            "Epoch  3/5: Train Acc=0.9904 | Test Acc=0.6583\n",
            "Epoch  4/5: Train Acc=0.9958 | Test Acc=0.6833\n",
            "Epoch  5/5: Train Acc=0.9971 | Test Acc=0.6042\n",
            "\n",
            "=== Run: Aida for 10 epochs ===\n",
            "Epoch  1/10: Train Acc=0.7446 | Test Acc=0.5917\n",
            "Epoch  2/10: Train Acc=0.9646 | Test Acc=0.6458\n",
            "Epoch  3/10: Train Acc=0.9896 | Test Acc=0.6000\n",
            "Epoch  4/10: Train Acc=0.9754 | Test Acc=0.6875\n",
            "Epoch  5/10: Train Acc=0.9946 | Test Acc=0.6792\n",
            "Epoch  6/10: Train Acc=0.9988 | Test Acc=0.6750\n",
            "Epoch  7/10: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch  8/10: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch  9/10: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 10/10: Train Acc=1.0000 | Test Acc=0.6833\n",
            "\n",
            "=== Run: Aida for 20 epochs ===\n",
            "Epoch  1/20: Train Acc=0.7596 | Test Acc=0.6667\n",
            "Epoch  2/20: Train Acc=0.9800 | Test Acc=0.7417\n",
            "Epoch  3/20: Train Acc=0.9871 | Test Acc=0.6833\n",
            "Epoch  4/20: Train Acc=0.9912 | Test Acc=0.7167\n",
            "Epoch  5/20: Train Acc=0.9962 | Test Acc=0.7792\n",
            "Epoch  6/20: Train Acc=1.0000 | Test Acc=0.7625\n",
            "Epoch  7/20: Train Acc=1.0000 | Test Acc=0.7792\n",
            "Epoch  8/20: Train Acc=1.0000 | Test Acc=0.7667\n",
            "Epoch  9/20: Train Acc=1.0000 | Test Acc=0.7667\n",
            "Epoch 10/20: Train Acc=1.0000 | Test Acc=0.7667\n",
            "Epoch 11/20: Train Acc=1.0000 | Test Acc=0.7667\n",
            "Epoch 12/20: Train Acc=1.0000 | Test Acc=0.7667\n",
            "Epoch 13/20: Train Acc=1.0000 | Test Acc=0.7708\n",
            "Epoch 14/20: Train Acc=1.0000 | Test Acc=0.7750\n",
            "Epoch 15/20: Train Acc=1.0000 | Test Acc=0.7750\n",
            "Epoch 16/20: Train Acc=1.0000 | Test Acc=0.7708\n",
            "Epoch 17/20: Train Acc=1.0000 | Test Acc=0.7708\n",
            "Epoch 18/20: Train Acc=1.0000 | Test Acc=0.7750\n",
            "Epoch 19/20: Train Acc=1.0000 | Test Acc=0.7750\n",
            "Epoch 20/20: Train Acc=1.0000 | Test Acc=0.7750\n",
            "\n",
            "=== Run: Aida for 40 epochs ===\n",
            "Epoch  1/40: Train Acc=0.7883 | Test Acc=0.6667\n",
            "Epoch  2/40: Train Acc=0.9654 | Test Acc=0.7583\n",
            "Epoch  3/40: Train Acc=0.9738 | Test Acc=0.7792\n",
            "Epoch  4/40: Train Acc=0.9946 | Test Acc=0.7792\n",
            "Epoch  5/40: Train Acc=0.9954 | Test Acc=0.7917\n",
            "Epoch  6/40: Train Acc=1.0000 | Test Acc=0.7917\n",
            "Epoch  7/40: Train Acc=1.0000 | Test Acc=0.7917\n",
            "Epoch  8/40: Train Acc=1.0000 | Test Acc=0.7875\n",
            "Epoch  9/40: Train Acc=1.0000 | Test Acc=0.7917\n",
            "Epoch 10/40: Train Acc=1.0000 | Test Acc=0.7708\n",
            "Epoch 11/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 12/40: Train Acc=1.0000 | Test Acc=0.7917\n",
            "Epoch 13/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 14/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 15/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 16/40: Train Acc=1.0000 | Test Acc=0.7875\n",
            "Epoch 17/40: Train Acc=1.0000 | Test Acc=0.7875\n",
            "Epoch 18/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 19/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 20/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 21/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 22/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 23/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 24/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 25/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 26/40: Train Acc=1.0000 | Test Acc=0.7792\n",
            "Epoch 27/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 28/40: Train Acc=1.0000 | Test Acc=0.7750\n",
            "Epoch 29/40: Train Acc=1.0000 | Test Acc=0.7792\n",
            "Epoch 30/40: Train Acc=1.0000 | Test Acc=0.7792\n",
            "Epoch 31/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 32/40: Train Acc=1.0000 | Test Acc=0.7833\n",
            "Epoch 33/40: Train Acc=1.0000 | Test Acc=0.7875\n",
            "Epoch 34/40: Train Acc=1.0000 | Test Acc=0.7917\n",
            "Epoch 35/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "Epoch 36/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "Epoch 37/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "Epoch 38/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "Epoch 39/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "Epoch 40/40: Train Acc=1.0000 | Test Acc=0.7958\n",
            "\n",
            "=== Run: Aida for 60 epochs ===\n",
            "Epoch  1/60: Train Acc=0.7525 | Test Acc=0.6167\n",
            "Epoch  2/60: Train Acc=0.9867 | Test Acc=0.7208\n",
            "Epoch  3/60: Train Acc=0.9808 | Test Acc=0.6042\n",
            "Epoch  4/60: Train Acc=0.9850 | Test Acc=0.6583\n",
            "Epoch  5/60: Train Acc=0.9988 | Test Acc=0.7042\n",
            "Epoch  6/60: Train Acc=0.9996 | Test Acc=0.6958\n",
            "Epoch  7/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch  8/60: Train Acc=1.0000 | Test Acc=0.7000\n",
            "Epoch  9/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 10/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 11/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 12/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 13/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 14/60: Train Acc=1.0000 | Test Acc=0.6500\n",
            "Epoch 15/60: Train Acc=1.0000 | Test Acc=0.6625\n",
            "Epoch 16/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 17/60: Train Acc=1.0000 | Test Acc=0.6708\n",
            "Epoch 18/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 19/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 20/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 21/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 22/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 23/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 24/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 25/60: Train Acc=1.0000 | Test Acc=0.6792\n",
            "Epoch 26/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 27/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 28/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 29/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 30/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 31/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 32/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 33/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 34/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 35/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 36/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 37/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 38/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 39/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 40/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 41/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 42/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 43/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 44/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 45/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 46/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 47/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 48/60: Train Acc=1.0000 | Test Acc=0.6917\n",
            "Epoch 49/60: Train Acc=1.0000 | Test Acc=0.6917\n",
            "Epoch 50/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 51/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 52/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 53/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 54/60: Train Acc=1.0000 | Test Acc=0.6833\n",
            "Epoch 55/60: Train Acc=1.0000 | Test Acc=0.6875\n",
            "Epoch 56/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 57/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 58/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 59/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "Epoch 60/60: Train Acc=1.0000 | Test Acc=0.6958\n",
            "\n",
            "All runs complete.\n",
            "Confusion matrices -> /content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Confusion Matrices\n",
            "Confidence images  -> /content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Confidence Scores\n",
            "Metrics CSV        -> /content/drive/MyDrive/Applied Machine Learning/Results/CNNs/VGG-19/Performance Metrics/VGG-19_RIC.csv\n"
          ]
        }
      ]
    }
  ]
}